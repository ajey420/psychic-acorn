{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q google \n",
    "! pip install -q google-generativeai\n",
    "! pip install -q google-ai-generativelanguage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key = 'AIzaSyDo1sNm4HPZChwKZLwYlirllcX2pKXHDl0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('out/_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content([img , prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This image is a diagram that shows the architecture of a transformer, which is a type of deep learning model that is commonly used in natural language processing (NLP). The diagram shows the different components of a transformer and how they are connected to each other. \\n\\nStarting from the bottom of the image, the input is first processed through an **input embedding** layer, which converts words into numerical vectors. The input embedding is then passed through a **positional encoding** layer that adds information about the position of each word in the input sequence. \\n\\nThe output of the positional encoding layer is then fed into the core of the transformer, which consists of multiple stacked **encoder-decoder** layers. Each encoder-decoder layer consists of two main components: an **encoder** and a **decoder**.\\n\\nThe encoder is responsible for processing the input sequence and generating a representation of it. The encoder layer consists of the following components:\\n\\n- **Multi-Head Attention:** This layer allows the model to attend to different parts of the input sequence and learn relationships between them.\\n- **Add & Norm:** This layer adds a residual connection to the attention layer, which helps to prevent vanishing gradients and improve the performance of the model.\\n- **Feed Forward:** This layer applies a fully connected neural network to the attention output, further processing the information and potentially extracting more complex features.\\n\\nThe decoder is responsible for generating the output sequence based on the encoded representation. The decoder layer consists of the following components:\\n\\n- **Masked Multi-Head Attention:** This layer allows the decoder to attend to the output sequence, but it is masked to prevent the model from attending to future tokens (tokens that haven't been generated yet).\\n- **Add & Norm:** This layer adds a residual connection to the masked attention layer.\\n- **Feed Forward:** This layer applies a fully connected neural network to the masked attention output.\\n- **Multi-Head Attention:**  This allows the decoder to attend to the encoded representation from the encoder, helping it to align the output sequence with the input sequence.\\n\\nThe output of the decoder is then passed through a **linear** layer that maps the output representation to a probability distribution over the vocabulary. Finally, the probability distribution is processed through a **softmax** layer that converts it into a set of probabilities, where each probability represents the likelihood of each word in the vocabulary being the next word in the output sequence.\\n\\n\\nThe image also highlights the key components of the model:\\n\\n- **Input Embedding:** Converts words into numerical vectors\\n- **Positional Encoding:** Adds information about the position of each word in the input sequence\\n- **Encoder:** Processes the input sequence and generates a representation of it\\n- **Decoder:** Generates the output sequence based on the encoded representation\\n- **Linear:** Maps the output representation to a probability distribution over the vocabulary\\n- **Softmax:** Converts the probability distribution into a set of probabilities, representing the likelihood of each word in the vocabulary being the next word in the output sequence\\n\\nThe image is a good visual representation of the transformer architecture. It helps to understand the different components of the model and how they are connected to each other.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
